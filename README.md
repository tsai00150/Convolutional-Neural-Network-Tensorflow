# Convolutional-Neural-Network-Tensorflow

å°çµ„çµ„å“¡ï¼šè¬é‡‡è¾°ã€ææœ‹æ³°ã€å¼µå®¶é½Šã€æº«ç¥å®‡\
ä»¥ä¸‹å…§å®¹ä¹‹ç¨‹å¼ç¢¼æºè‡ªæ–¼Tensorflowå®˜ç¶²çš„CNNæ•™å­¸ç¯„æœ¬ï¼Œæ‰€æœ‰ç¨‹å¼çš†ä»¥æ­¤ç‚ºåŸºç¤é€²è¡Œæ”¹å¯«ï¼Œé€£çµå¦‚ä¸‹ğŸ‘‡\
https://www.tensorflow.org/tutorials/images/cnn?hl=zh-tw


## ä¸€ã€Tensorflow èˆ‡ Kerasç°¡ä»‹

Tensrflowæ˜¯ä¸€å€‹ç”±Googleæ——ä¸‹çš„åœ˜éšŠã€ŒGoogle Brain Teamã€æ‰€é–‹ç™¼çš„é–‹æ”¾åŸå§‹ç¢¼è»Ÿé«”è³‡æ–™åº«ï¼Œæ–¼2015å¹´11æœˆé‡‹å‡ºåˆå§‹ç‰ˆæœ¬ï¼Œéš¨å¾Œè¢«50å€‹é–‹ç™¼åœ˜éšŠæ¡ç”¨ï¼Œå»£ç”¨æ–¼è£½ä½œGoogleèˆ‡ç›¸é—œçš„å•†æ¥­ç”¢å“çš„æ©Ÿå™¨å­¸ç¿’å·¥å…·ï¼Œä¾¿å–ä»£äº†Googleåœ¨2010å¹´é–‹å§‹ä½¿ç”¨çš„ç¬¬ä¸€ä»£æ©Ÿå™¨å­¸ç¿’ç³»çµ±ã€ŒDistBeliefã€çš„æ·±åº¦å­¸ç¿’ä»»å‹™ï¼Œæˆç‚ºå¾ˆå¤šæˆ‘å€‘æ—¥å¸¸ç”Ÿæ´»ä¸­ç¿’ä»¥ç‚ºå¸¸çš„æœå‹™åŠŸèƒ½ï¼Œä¾‹å¦‚Gmailéæ¿¾åƒåœ¾ä¿¡ã€Googleç¿»è­¯ã€Googleæœå°‹ã€GoogleèªéŸ³æœå°‹ã€GoogleèªéŸ³è¾¨è­˜ã€Googleåœ–ç‰‡è¾¨è­˜ã€Googleç›¸ç°¿ã€Googleåœ°åœ–ã€Googleè¡—æ™¯ã€YouTubeå’Œç¶²é å»£å‘ŠæŠ•æ”¾......ç­‰ç­‰ã€‚\
TensorFlowå–åéˆæ„Ÿä¾†è‡ªæ–¼å°å¤šç¶­é™£åˆ—åŸ·è¡Œçš„æ“ä½œï¼Œé€™äº›å¤šç¶­é™£åˆ—è¢«ç¨±ç‚ºå¼µé‡(Tensor)ï¼Œé€éé‹ç®—å¼µé‡æ¨¡æ“¬ç¥ç¶“ç¶²è·¯ï¼Œè€Œå®ƒä¸»è¦å°±æ˜¯è¦è—‰ç”±å¯¦ç¾é«˜å¼·åº¦çš„çŸ©é™£é‹ç®—å»é”åˆ°æ©Ÿå™¨å­¸ç¿’çš„æœ€é«˜æ•ˆèƒ½ï¼Œè€Œå®ƒçš„å¦ä¸€å€‹å„ªé»æ˜¯è®“ä¸åŒå¹³å°ã€ä½œæ¥­ç³»çµ±å’Œèªè¨€çš„ç”¨æˆ¶éƒ½èƒ½ä¸ä¿®æ”¹ç¨‹å¼ç¢¼ç›´æ¥ä½¿ç”¨ï¼Œå®ƒçš„åº•å±¤æ ¸å¿ƒå¼•æ“ç”±C++å¯¦ç¾ï¼Œé€šégRPCå¯¦ç¾ç¶²è·¯äº’è¨ªã€åˆ†æ•£å¼åŸ·è¡Œï¼Œä¸¦ä¸”æä¾›äº†ä¸€å€‹Python APIï¼Œä»¥åŠC++ã€Haskellã€Javaã€Goå’ŒRustç­‰ç­‰å…¶ä»–èªè¨€çš„ APIï¼Œè‹¥ä½¿ç”¨ç¬¬ä¸‰æ–¹ç¨‹å¼é‚„å¯ç”¨æ–¼ C#ã€.NET Coreã€Juliaã€Rå’ŒScalaã€‚\
é›–ç„¶å®ƒçš„Pythonã€C++å’ŒJavaçš„APIå…±äº«äº†å¤§éƒ¨åˆ†åŸ·è¡Œä»£ç¢¼ï¼Œä½†æ˜¯æœ‰é—œæ–¼åå‘å‚³æ’­æ¢¯åº¦è¨ˆç®—çš„éƒ¨åˆ†ä»ç„¶éœ€è¦åœ¨ä¸åŒèªè¨€å–®ç¨å¯¦ç¾ï¼Œè€Œç›®å‰åªæœ‰Python APIè¼ƒç‚ºè±å¯Œçš„å¯¦ç¾äº†åå‘å‚³æ’­éƒ¨åˆ†ï¼Œæ‰€ä»¥å¤§å¤šæ•¸äººï¼ŒåŒ…æ‹¬æˆ‘å€‘çš„é€™æ¬¡å ±å‘Šéƒ½æ˜¯ä½¿ç”¨Pythoné€²è¡Œæ¨¡å‹è¨“ç·´ï¼Œä½†æ˜¯ä¾ç„¶å¯ä»¥é¸æ“‡ä½¿ç”¨å…¶å®ƒèªè¨€é€²è¡Œç·šä¸Šæ¨ç†ã€‚

![Alt text](readme-images/img0.jpg?raw=true "Title")

ç”±æ–¼Tensorflowå±¬æ–¼æ¯”è¼ƒä½éšçš„æ·±åº¦å­¸ç¿’APIï¼Œå¥½è™•æ˜¯ç›¸ç•¶éˆæ´»ï¼Œå¯é©æ‡‰å„ç¨®æ‡‰ç”¨ï¼Œæ­é…å„ç¨®è¨­è¨ˆã€‚ç¼ºé»å°±æ˜¯åœ¨è¨­è¨ˆæ¨¡å‹æ™‚ï¼Œåƒæ˜¯å¼µé‡ä¹˜ç©ã€å·ç©ç­‰ç­‰åŸºç¤æ“ä½œçµ±çµ±éƒ½å¾—ä½¿ç”¨è€…è‡ªå·±ä¾†è™•ç†ï¼Œç›¸ç•¶è²»æ™‚ï¼Œè€Œä¸”åˆå­¸è€…è¼ƒé›£ç†è§£èˆ‡å­¸ç¿’ã€‚æ–¼æ˜¯é–‹ç™¼ç¤¾ç¾¤å°±ä»¥Tensorflowç‚ºåŸºç¤ï¼Œé€²è€Œé–‹ç™¼é«˜éšæ·±åº¦å­¸ç¿’APIï¼Œè®“ç”¨æˆ¶å¯ä»¥ä½¿ç”¨æ›´ç°¡æ½”çš„æ–¹å¼å»å»ºç«‹æ¨¡å‹ï¼Œå…¶ä¸­æœ€å®Œæ•´çš„è«éæ–¼ã€ŒKerasã€ã€‚\
Kerasæ˜¯ä¸€å€‹é–‹æ”¾åŸå§‹ç¢¼ï¼Œé«˜éšçš„æ·±åº¦å­¸ç¿’ç¨‹å¼åº«ï¼Œä½¿ç”¨Pythonç·¨å¯«ï¼Œæ—¨åœ¨å¿«é€Ÿå¯¦ç¾åŒ…å«å·ç©ç¥ç¶“ç¶²è·¯åœ¨å…§çš„å„ç¨®æ·±åº¦ç¥ç¶“ç¶²è·¯ï¼Œä¸¦å°ˆæ³¨æ–¼ç”¨æˆ¶å‹å¥½ã€æ¨¡çµ„åŒ–å’Œå¯å»¶ä¼¸æ€§ã€‚å…¶ä»£ç¢¼æ”¾åœ¨GitHubä¸Šï¼ŒåŒ…å«è¨±å¤šå¸¸ç”¨ç¥ç¶“ç¶²è·¯æ§‹å»ºå¡Šçš„å¯¦ç¾ï¼Œä¾‹å¦‚å±¤ã€ç›®æ¨™ã€å•Ÿç”¨åŠŸèƒ½ã€å„ªåŒ–å™¨å’Œä¸€ç³»åˆ—å·¥å…·ï¼Œå…¶ä»–å¸¸è¦‹çš„å¯¦ç”¨å…¬å…±å±¤æ”¯æ´é‚„æœ‰Dropoutèˆ‡æ± åŒ–å±¤ç­‰ç­‰ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥æ›´è¼•é¬†åœ°è™•ç†åœ–åƒå’Œæ–‡å­—è³‡æ–™ã€‚\
è‡ª2015å¹´3æœˆé‡‹å‡ºç¬¬ä¸€ç‰ˆä¹‹å¾Œé–‹å§‹å—åˆ°æ·±åº¦å­¸ç¿’çš„å­¸ç¿’è€…æ„›ç”¨ï¼Œæ–¼2017å¹´é–‹å§‹æ¥å—Googleåœ˜éšŠçš„æ”¯æ´ï¼Œå¾—ä»¥ç”¨TensorFlowä½œç‚ºå¾Œç«¯å¼•æ“ï¼Œå…©è€…æ­é…å°‡ä½¿å»ºç«‹æ·±åº¦å­¸ç¿’æ¨¡å‹èˆ‡é€²è¡Œè¨“ç·´ã€é æ¸¬æ›´åŠ å¿«é€Ÿå’Œç°¡æ˜“ã€‚

![Alt text](readme-images/img1.jpg?raw=true "Title")

é€éKerasæ‰€æä¾›çš„å„é …æ¨¡çµ„å·¥å…·ï¼Œä¾‹å¦‚å·ç©å’Œæ± åŒ–æ¨¡çµ„ï¼Œæˆ‘å€‘å¾—ä»¥è¼ƒè¼•é¬†åœ°æ“ä½œä¸€å€‹é¡ä¼¼ä¸Šåœ–çµæ§‹çš„ç¥ç¶“ç¶²è·¯ï¼Œä¸¦é€éèª¿æ•´å„å€‹ç´°ç¯€çš„æ”¹è®Šå»ç ”ç©¶æ¯å€‹ç’°ç¯€å°è¨“ç·´èˆ‡é æ¸¬æœƒé€ æˆé‚£äº›å½±éŸ¿ã€‚

## äºŒã€Tensorflowèˆ‡VGG-16ç¯„ä¾‹ ä»‹ç´¹

### (1)Tensorflow èªæ³•ä»‹ç´¹
ä»¥ä¸‹æ˜¯æˆ‘å€‘å ±å‘Šä¹‹ä¸­æ‰€é‹è¡Œçš„åŸºæœ¬ç¨‹å¼ç¢¼ï¼š
```py
#ç¬¬ä¸€æ­¥å…ˆå°å…¥Tensorflowã€Keraså’ŒMatplotlib
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
from tensorflow.keras import datasets, layers, models, initializers
import matplotlib.pyplot as plt
import random

#æ¥è‘—æŠŠåœ–ç‰‡å¾è³‡æ–™åº«ä¸­æŠ“ä¸‹ä¾†ä¸¦åˆ†æˆåå€‹é¡åˆ¥
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

#å†ä¾†æ˜¯å»ºç«‹é‹ç®—æ¨¡å‹ï¼Œç¶“éä¸‰æ¬¡å·ç©èˆ‡å…©æ¬¡æ± åŒ–ï¼Œç°¡åŒ–é‹ç®—æ•ˆç‡
#ç”¨reluå‡½æ•¸ä½¿è² å€¼æ”¹ç‚º0ï¼Œé¿å…é™°å½±ï¼Œçªç¾åœ–åƒçš„è¼ªå»“
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

#é€éå¹³å¦å±¤(Flatten Layer)å°‡è¼¸å‡ºå£“æˆä¸€ç¶­åœ–åƒ
#å›æ­¸è‡³å…¨é€£éšå±¤(Dense Layer)é€²è¡Œåˆ†é¡
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))
model.summary()

#ä½¿ç”¨adamæ­¤ä¸€å„ªåŒ–å™¨(Optimizer)ï¼Œç·¨è­¯å’Œè¨“ç·´æ­¤æ¨¡å‹ï¼Œä¸¦å»ºç«‹èµ·åœ–åƒçµæ§‹
#æœ‰50000å¼µåœ–ç‰‡ç”¨æ–¼è¨“ç·´ï¼Œ10000å¼µåœ–ç‰‡ç”¨æ–¼æ¸¬è©¦
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))
print(model.metrics_names)

#æœ€å¾Œï¼Œç¹ªè£½å‡ºå±•ç¤ºè¨“ç·´æº–ç¢ºåº¦å’Œæ¸¬è©¦æº–ç¢ºåº¦çš„åœ–è¡¨
plt.plot(history.history['acc'], label='acc')
plt.plot(history.history['val_acc'], label = 'val_acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
print(test_acc)

#ç¹ªè£½çµæœç¯„ä¾‹å¦‚ä¸‹
```
![Alt text](readme-images/img2.png?raw=true "Title")

### (2)VGG-16ä»‹ç´¹
ä¸‹åˆ—ç‚ºVGG-16å¥—ç”¨æ–¼Tensorflowä¸‹çš„çµ„æˆç¨‹å¼ç¢¼ï¼š
```
model = models.Sequential()

model.add(layers.Conv2D(64, (3, 3), activation='relu', 
input_shape=(32, 32, 3), padding="same"))
model.add(layers.Conv2D(64, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPooling2D((2, 2), strides=(2,2)))

model.add(layers.Conv2D(128, (3, 3), activation='relu', padding="same"))
model.add(layers.Conv2D(128, (3, 3), activation="relu", padding="same"))
model.add(layers.MaxPooling2D((2, 2), strides=(2,2)))

model.add(layers.Conv2D(256, (3, 3), activation='relu', padding="same"))
model.add(layers.Conv2D(256, (3, 3), activation='relu', padding="same"))
model.add(layers.Conv2D(256, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPooling2D((2, 2), strides=(2,2)))

model.add(layers.Conv2D(512, (3, 3), activation="relu", padding="same"))
model.add(layers.Conv2D(512, (3, 3), activation="relu", padding="same"))
model.add(layers.Conv2D(512, (3, 3), activation="relu", padding="same"))
model.add(layers.MaxPooling2D((2, 2), strides=(2,2)))

model.add(layers.Conv2D(512, (3, 3), activation="relu", padding="same"))
model.add(layers.Conv2D(512, (3, 3), activation="relu", padding="same"))
model.add(layers.Conv2D(512, (3, 3), activation="relu", padding="same"))
model.add(layers.MaxPooling2D((2, 2), strides=(2,2)))
```
ä¾†æºï¼šhttps://ithelp.ithome.com.tw/articles/10192162

åœ–ï¼šVGG-16ç¤ºæ„åœ–
![Alt text](readme-images/img3.jpg?raw=true "Title")\
è¨“ç·´çµæœï¼š
**loss: 2.3028 - acc: 0.0983 - val_loss: 2.3027 - val_acc: 0.1000**\
å°‡Epochè¨­å®šç‚º6ä¹‹å¾Œï¼Œæ‰€å¾—çµæœå»ä¸å¦‚é æœŸï¼Œè¨“ç·´æº–ç¢ºåº¦ä¸€ç›´åœ¨0.0973èˆ‡0.0991ä¹‹é–“éŠèµ°ï¼Œè‡³æ–¼æ¸¬è©¦æº–ç¢ºåº¦å‰‡æ˜¯å¾ˆå›ºå®šç¶­æŒåœ¨0.1ã€‚åœ¨ä¸€èˆ¬çš„é›»è…¦ä¸Šå»åšè¨“ç·´çš„æ™‚é–“ä¹Ÿç›¸ç•¶é•·ï¼Œå¹³å‡æ¯è¨“ç·´å®Œä¸€æ¬¡å°±è¦å ç”¨30åˆ†é˜çš„æ™‚é–“ã€‚\

ç‚ºäº†äº†è§£é€™å€‹ç¾è±¡ï¼Œæˆ‘å€‘å°‡VGG-16çš„å±¤æ•¸æ¸›å°‘ï¼Œä¸¦ä¸”å†è·‘ä¸€æ¬¡ã€‚æ›´æ”¹çš„é …ç›®ä»¥åŠçµæœå¦‚ä¸‹ï¼š
```py
model = models.Sequential()

model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), padding="same"))
model.add(layers.Conv2D(64, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPooling2D((2, 2), strides=(2,2)))

model.add(layers.Conv2D(128, (3, 3), activation='relu', padding="same"))
model.add(layers.Conv2D(128, (3, 3), activation="relu", padding="same"))
model.add(layers.MaxPooling2D((2, 2), strides=(2,2)))

model.add(layers.Conv2D(256, (3, 3), activation='relu', padding="same"))
model.add(layers.Conv2D(256, (3, 3), activation='relu', padding="same"))
model.add(layers.Conv2D(256, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPooling2D((2, 2), strides=(2,2)))
# æ¸›å°‘å…­å€‹Conv2Då±¤ã€å…©å€‹MaxPoolingå±¤ã€å…±å…«å±¤
model.add(layers.Flatten())
model.add(layers.Dense(4096, activation='relu'))
#æ¸›å°‘ä¸€å€‹Denseå±¤
model.add(layers.Dense(10, activation='softmax'))
```
è¨“ç·´çµæœï¼š
**loss: 0.6019 - acc: 0.7874 - val_loss: 0.7636 - val_acc: 0.7388**\
ä¸é›£ç™¼ç¾ï¼Œè¨“ç·´çµæœæ¯”èµ·æŠŠæ‰€æœ‰çš„VGG-16éƒ½å¥—ç”¨é€²CIFAR-10è³‡æ–™åº«å…§å¥½å¾ˆå¤šï¼Œç”šè‡³æ¯”åŸæœ¬å®˜ç¶²æ‰€æä¾›å°‡è¿‘70%çš„æº–ç¢ºåº¦é«˜å‡ºäº›è¨±ï¼›è‡³æ–¼è¨“ç·´çš„é€Ÿåº¦ï¼Œä¹Ÿæ˜¯ç”±å±¤æ•¸è¼ƒå°‘çš„ç‰ˆæœ¬å‹å‡ºã€‚è‡³æ–¼ç‚ºä½•å±¤æ•¸è¼ƒå°‘çš„ç‰ˆæœ¬åè€ŒåŸ·è¡Œèµ·ä¾†çš„æº–ç¢ºåº¦é«˜å‡ºè¨±å¤š?ç¶“éæˆ‘å€‘çµ„å…§è¨è«–ï¼Œé€™åŸå› å¯ä»¥å¾Stanfordçš„CNNæ•™æä¸­ç²å¾—è§£ç­”ã€‚åœ¨ç¬¬ä¹ç« ä¸­çš„ç¬¬81å¼µæŠ•å½±ç‰‡æåˆ°ï¼Œè‹¥æ˜¯å¢åŠ å¤ªå¤šå±¤ç¥ç¶“ç¶²è·¯ï¼Œåœ¨è³‡æ–™é‡ä¸æ˜¯ç‰¹åˆ¥é«˜çš„è¨“ç·´åº«ä¸­çš„æƒ…å½¢ä¸‹ï¼Œåè€Œæœƒå¢åŠ éŒ¯èª¤ç‡ã€‚CIFAR-10ä¸­çš„æ¯ä¸€å¼µåœ–çš†æ˜¯32x32çš„pixelæ•¸ï¼Œä½†æ˜¯VGG-16ç•¶åˆè¨­è¨ˆå»æ˜¯è¼¸å…¥224x224çš„å½±åƒåœ–ï¼Œæˆ‘å€‘èªç‚ºè¨Šæ¯é‡ä¸Šçš„è½å·®æœƒå°è‡´CIFAR-10çš„è³‡æ–™è¢«éåº¦è§£æï¼Œéå¤šçš„å±¤æ•¸ä¹Ÿå°è‡´ç¥ç¶“ç¶²è·¯ç„¡æ³•å¥½å¥½è¨“ç·´ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œæ­¤æƒ…æ³ä¸¦éoverfiitingï¼Œå› ç‚ºæº–ç¢ºåº¦ä¸¦æ²’æœ‰å› ç‚ºè¨“ç·´æ¬¡æ•¸éå¤šè€Œé™ä½--å®ƒæœ¬ä¾†å°±ä¸€ç›´è™•æ–¼æ¥µä½çš„æƒ…æ³ã€‚
åœ–ï¼šStanfordçš„CNNæ•™æ
![Alt text](readme-images/img4.jpg?raw=true "Title")

## ä¸‰ã€è®Šæ•¸ä¿®æ”¹èˆ‡çµæœ
### (1)èª¿æ•´Epochçš„æ•¸é‡
æˆ‘å€‘é€éèª¿æ•´epochçš„æ•¸é‡ä¾†è§€å¯Ÿæ¨¡å‹æº–ç¢ºç‡çš„è®ŠåŒ–ï¼Œä»¥epochæ•¸é‡5,10,15,20,25,30ä¾†åšæ¸¬è©¦ï¼Œæ¯å€‹æ•¸é‡å‡ä»¥ç¨‹å¼å„è·‘5æ¬¡ä¾†æ±‚å‡ºå¹³å‡ï¼š\
epoch = 5, accuracy = 0.6901\
epoch = 10, accuracy = 0.7143\
epoch = 15, accuracy = 0.7023\
epoch = 20, accuracy = 0.7001\
epoch = 25, accuracy = 0.6988\
epoch = 30, accuracy = 0.6885\
å¯ä»¥çœ‹å‡ºåœ¨æ•¸é‡é”åˆ°15ä»¥ä¸Šä¹‹å¾Œï¼Œæº–ç¢ºç‡åè€Œä¸‹æ»‘ã€‚
å¾Œä¾†æˆ‘å€‘é‡å°epoch = 10åšé€²ä¸€æ­¥æ¸¬è©¦ï¼Œåˆ—å‡º5,8,9,10,11,12,15å€‹çš„æ¸¬è©¦ã€‚
å¹³å‡å€¼ç‚ºï¼š\
epoch = 5, accuracy = 0.6911\
epoch = 8, accuracy = 0.6975\
epoch = 9, accuracy = 0.6997\
epoch = 10, accuracy = 0.7115\
epoch = 11, accuracy = 0.7056\
epoch = 12, accuracy = 0.7090\
epoch = 15, accuracy = 0.7043\
ä¾ç„¶æ˜¯epoch = 10ç‚ºæœ€é«˜é»ï¼Œå› æ­¤æˆ‘å€‘è¦ºå¾—ï¼Œepochæ•¸é‡è‹¥å¤§æ–¼10å€‹ï¼Œåœ¨æ­¤æ¨¡å‹å°±æœƒç”¢ç”Ÿover fittingçš„ç¾è±¡ï¼Œé€²è€Œå°è‡´æº–ç¢ºç‡ä¸‹é™ã€‚

### (2)Learning Rate
é€éæ›´æ”¹æ­¥è·ä¾†è§€å¯Ÿæº–ç¢ºç‡çš„è®ŠåŒ–ï¼Œç‚ºäº†æ›´æ”¹æ­¥è·ï¼Œå¿…é ˆimport optimizersï¼š
```py
from keras import optimizers
# compile modelæ™‚è¨­å®šadamçš„learning rate, æˆ‘å€‘åˆ†åˆ¥æ¸¬è©¦äº†0.1, 0.01, 0.001, 0.0001å››ç¨®
adam = optimizers.Adam(lr=learning rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
model.compile(optimizer='adam',
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
```
ä»¥ä¸‹æ˜¯æ¸¬è©¦çµæœï¼š\
Lr = 0.1, Test Accuracy = 0.6871\
Lr = 0.01, Test Accuracy = 0.7164\
Lr = 0.001, Test Accuracy = 0.7060\
Lr = 0.0001, Test Accuracy = 0.6774\
å¾æ¸¬è©¦çµæœä¾†çœ‹ï¼Œå°æ–¼é€™å€‹æ¨¡å‹ä¾†èªªï¼ŒLearning rate = 0.01æ‰€å¾—å‡ºçš„æº–ç¢ºç‡æ˜¯æœ€é«˜çš„ï¼Œå› æ­¤è¨­ç‚ºå°‡æ­¥è·è¨­ç‚º0.01æœ€ç‚ºåˆé©æˆ‘å€‘çš„dataã€‚

### (3)Data Preprocessing
å®Œæ•´ç¨‹å¼ç¢¼ï¼š```Data Preprocessing.ipynb```\
å°‡è³‡æ–™å…ˆç¶“éé å…ˆè™•ç†ï¼Œæ¨™æº–åŒ–è³‡æ–™ä¹‹å¾Œï¼Œèƒ½å¤ å„ªåŒ–æˆ‘å€‘çš„æ¨¡å‹ï¼›
è¼‰å…¥è³‡æ–™åº«çš„åœ–ç‰‡å¾Œï¼Œå°åœ–ç‰‡åšæ¨™æº–åŒ–ç•¶ä½œpreprocessingï¼š
```py
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
def standardize(input):
    mean = np.mean(input)
    std = np.std(input)
    return (input - mean) / std
train_images, test_images = standardize(train_images)  , standardize(test_images)
```
ä»¥ä¸‹æ˜¯æ¸¬è©¦çµæœï¼š\
**loss: 0.7044 - acc: 0.7550 - val_loss: 0.8190 - val_acc: 0.7184**\
Test Accuracy = 0.7184\
ç›¸è¼ƒä¹‹ä¸‹ï¼Œé€²è¡Œédata preprocessingçš„æ¨¡å‹é æ¸¬æº–ç¢ºç‡ï¼Œæé«˜äº†å¤§ç´„4~5å€‹ç™¾åˆ†é»ï¼Œæ•ˆæœç›¸ç•¶é¡¯è‘—ã€‚

### (4)Weight Initialization
æ·±åº¦å­¸ç¿’æ¨¡å‹è¨“ç·´çš„éç¨‹æœ¬èº«å°±æ˜¯åœ¨èª¿æ•´weightçš„å¤§å°ï¼Œä½†å¦‚ä½•é¸æ“‡åƒæ•¸åˆå§‹å€¼å°±æ˜¯ä¸€å€‹é‡è¦çš„ç’°ç¯€ï¼Œå› ç‚ºå°æ–¼çµæ§‹é¾å¤§çš„å­¸ç¿’æ¨¡å‹ï¼Œéç·šæ€§å‡½æ•¸ä¸æ–·ç–ŠåŠ ï¼Œå› æ­¤é¸æ“‡è‰¯å¥½çš„åˆå§‹å€¼å¯å¤§å¤§å¢åŠ æ¨¡å‹çš„æ•ˆç‡ã€‚\
æˆ‘å€‘é¸æ“‡äº†å…©ç¨®initial functionä¾†ä»‹ç´¹ï¼š
#### i. Random initialization
åœ¨convolutional, dense layeråšåˆå§‹åŒ–ï¼š
```py
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), 
                       kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', 
                       kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', 
                       kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu', 
                      kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))
model.add(layers.Dense(10, activation='softmax', 
                      kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))
```
æ¸¬è©¦çµæœï¼š\
**loss: 0.8697 - acc: 0.6945 - val_loss: 0.9320 - val_acc: 0.6710**\
Test Accuracy = 0.6710
#### ii. Truncated initialization
åœ¨convolutional, dense layeråšåˆå§‹åŒ–ï¼š
```py
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), 
                       kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', 
                       kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', 
                       kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu', 
                      kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)))
model.add(layers.Dense(10, activation='softmax', 
                      kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)))
```
æ¸¬è©¦çµæœï¼š\
**loss: 0.8825 - acc: 0.6868 - val_loss: 0.9490 - val_acc: 0.6715**\
Test Accuracy = 0.6715\
ç”±æ¸¬è©¦çµæœå¾—çŸ¥ï¼Œé€™å…©å€‹weight initializationçš„æ•ˆæœå°æ–¼æˆ‘å€‘çš„æ¨¡å‹æº–ç¢ºåº¦çš†æ²’æœ‰é¡¯è‘—çš„å½±éŸ¿ã€‚

### (5)Batch Normalization
æ˜¯å°‡åˆ†æ•£çš„æ•¸æ“šçµ±ä¸€æ¨™æº–åŒ–çš„ä¸€ç¨®åšæ³•ï¼ŒåŒæ¨£çš„èƒ½å¤ å„ªåŒ–æˆ‘å€‘çš„ç¥ç¶“ç¶²è·¯ã€‚å°‡batch functionåŠ åœ¨maxpooling, dense layerä¹‹å¾Œï¼š
```py
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='sigmoid', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.BatchNormalization())
model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.BatchNormalization())
model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='sigmoid'))
model.add(layers.BatchNormalization())
model.add(layers.Dense(10, activation='softmax'))
```
æ¸¬è©¦çµæœï¼š
**loss: 0.7193 - acc: 0.7504 - val_loss: 0.9392 - val_acc: 0.6816**\
Test Accuracy = 0.6816\
ç”±æ¸¬è©¦çµæœå¯çœ‹å‡ºï¼Œbatch normalizationçš„æ•ˆæœå°æ–¼æˆ‘å€‘çš„æ¨¡å‹ä¸¦æ²’æœ‰é¡¯è‘—çš„å½±éŸ¿ã€‚

### (6)Optimizerçš„èª¿æ•´
Optimizerå°æ–¼ä¸€å€‹å­¸ç¿’æ¨¡å‹ä¾†èªªç›¸ç•¶é‡è¦ï¼Œéš¨è‘—æŠ€è¡“æ¼”åŒ–ï¼Œæ–°é–‹ç™¼å‡ºçš„Optimizerå¯ä»¥å¾—åˆ°æ›´é«˜çš„æº–ç¢ºåº¦ä»¥åŠæ›´å¿«çš„é€Ÿåº¦ã€‚
#### i.ä½¿ç”¨Adadelta
```py
model.compile(optimizer='Adadelta', # é è¨­ç‚ºlr=1.0, rho=0.95, epsilon=1e-06
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
```
Test Accuracy = 0.7339
#### ii.ä½¿ç”¨Adagrad
```py
model.compile(optimizer='Adagrad', # é è¨­ç‚ºlr=0.01, epsilon=1e-06
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
```
Test Accuracy = 0.7436
#### iii.ä½¿ç”¨RMSprop
```py
model.compile(optimizer='RMSprop', # é è¨­ç‚ºlr=0.001, rho=0.9, epsilon=1e-06
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
```
Test Accuracy = 0.6951
#### iiii.ä½¿ç”¨sgd
```py
model.compile(optimizer='sgd', # é è¨­ç‚ºlr=0.01, momentum=0.0, decay=0.0, nesterov=False
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
```
Test Accuracy = 0.5637\
å†åŠ ä¸Šæˆ‘å€‘åŸæœ¬ä½¿ç”¨çš„adamï¼Œæˆ‘å€‘å…±æ¸¬è©¦äº†äº”ç¨®çš„optimizerï¼Œå¯çœ‹å‡ºå°æ–¼æˆ‘å€‘çš„è³‡æ–™ï¼Œæ¨¡å‹æº–ç¢ºç‡æœ€é«˜çš„ä¾åºæ˜¯Adagradã€Adadeltaã€RMSpropã€adamã€sgdï¼Œä½†é€™ä¸¦ä¸ä»£è¡¨æ‰€æœ‰è³‡æ–™éƒ½é©ç”¨æ–¼é€™å€‹çµè«–ã€‚

### (7)Dropout
ç•¶å­¸ç¿’æ¨¡å‹å®¹é‡éé«˜æˆ–è€…æ˜¯è¨“ç·´è³‡æ–™éå°‘å¾ˆå®¹æ˜“é€ æˆover fittingçš„å•é¡Œï¼Œé€™æ™‚å€™åˆ©ç”¨dropoutä»¥ä¸€å®šçš„æ©Ÿç‡ä¸Ÿæ£„éš±è—å±¤ç¥ç¶“å…ƒï¼Œé€™æ¨£åœ¨åå‘å‚³æ’­æ™‚ï¼Œè¢«ä¸Ÿæ£„çš„ç¥ç¶“å…ƒæ¢¯åº¦æ˜¯ 0ï¼Œæ‰€ä»¥åœ¨è¨“ç·´æ™‚ä¸æœƒéåº¦ä¾è³´æŸä¸€äº›ç¥ç¶“å…ƒï¼Œè—‰æ­¤é”åˆ°é é˜²over fittingçš„æ•ˆæœã€‚
#### i.å°‡dropoutæ©Ÿç‡è¨­ç‚º0.2
```py
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.2))
model.add(layers.Dense(10, activation='softmax'))
```
Test Accuracy = 0.6832
#### ii.å°‡dropoutæ©Ÿç‡è¨­ç‚º0.3
```py
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(10, activation='softmax'))
```
Test Accuracy = 0.6586
#### iii.å°‡dropoutæ©Ÿç‡è¨­ç‚º0.4
```py
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.4))
model.add(layers.Dense(10, activation='softmax'))
```
Test Accuracy = 0.6476
#### iiii.å°‡dropoutæ©Ÿç‡è¨­ç‚º0.5
```py
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(10, activation='softmax'))
```
Test Accuracy = 0.6554\
å¾çµæœçœ‹å‡ºï¼Œé™¤äº†dropout=0.22å¾—åˆ°çš„æº–ç¢ºç‡ç•¥é«˜ä¸€é»ä»¥å¤–ï¼Œå…¶é¤˜çš„çš†å·®ä¸åˆ°ä¸€å€‹ç™¾åˆ†é»ï¼Œå› æ­¤å°‡dropoutæ©Ÿç‡è¨­ç‚º0.2æ‡‰æ˜¯æœ€é©åˆæˆ‘å€‘çš„è³‡æ–™ã€‚

### (8) æœ€ä½³æ¨¡å‹
æˆ‘å€‘å°‡å€‹åˆ¥åƒæ•¸æœ€å¥½çš„çµæœæ”¾åœ¨ä¸€èµ·ï¼Œç™¼ç¾æº–ç¢ºç‡åè€Œä¸‹é™ï¼Œå¤§ç´„åœ¨0.52å·¦å³ï¼Œå¯è¦‹åƒæ•¸çš„è¨­å®šå¿…é ˆè¦–æƒ…æ³è€Œå®šï¼Œä¸¦æ²’æœ‰æ¨™æº–ç­”æ¡ˆã€‚
å› æ­¤ï¼Œæˆ‘å€‘æ ¹æ“šVGG16ç‚ºæ¨£æœ¬é€²è¡Œä¿®æ”¹ï¼Œå°‡å±¤æ•¸ç¸®å°ï¼ŒåŸå…ˆçš„VGG16æœ‰äº”å€‹blockï¼Œä½†å› æˆ‘å€‘è¼¸å…¥ä¹‹åœ–ç‰‡å¤§å°ç‚º32x32ï¼Œå› æ­¤ï¼Œæˆ‘å€‘åˆªæ‰è‡³ä¸‰å€‹blockã€‚è€Œå…¶ä»–åƒæ•¸ä¿æŒä¸è®Šï¼Œåƒæ˜¯filterç‚º3x3ã€å…©å±¤å·ç©ä¸€å±¤æ± åŒ–ã€æ¬Šé‡åˆå§‹åŒ–ç”¨he_normalã€reluç­‰ã€‚\
æ­¤å¤–ï¼Œæˆ‘å€‘é‚„æ¡ç”¨data preprocessingã€data augmentationã€dropoutç­‰æŠ€è¡“ï¼Œä»¥å¢åŠ è³‡æ–™é‡ä¸¦æ¸›å°‘overfittingçš„å•é¡Œã€‚
å®Œæ•´ç¨‹å¼ç¢¼åœ¨```OwnImageTest.ipynb```ä¸­ï¼›Test Accuracy = 0.7898

## å››ã€è‡ªè¡Œæ¸¬è©¦åœ–ç‰‡
è¨“ç·´å®Œæˆä¹‹å¾Œï¼Œå¯ä»¥ç”¨è‡ªèº«çš„åœ–ç‰‡ä¾†æ¸¬è©¦çµæœã€‚
é¦–å…ˆï¼Œåœ¨æ•´å€‹modelçš†å®Œæˆè¨“ç·´å¾Œï¼Œæ–°å¢ä¸€å€‹saveä¾†æŠŠç”¨CIFAR-10è¨“ç·´å®Œæˆçš„modelå­˜èµ·ä¾†ï¼š
```py
model.save('model.h5')
```
ç³»çµ±æœƒå°‡å®ƒå„²å­˜åœ¨å’ŒåŸ·è¡Œçš„.pyæª”åŒä¸€å€‹è³‡æ–™å¤¾ï¼Œè‹¥æœ‰é‡æ–°è¨“ç·´éï¼Œç³»çµ±æœƒå°‡å®ƒè¦†å¯«ã€‚
ä¸‹ä¸€æ­¥ï¼Œå‰‡æ˜¯å°‡ä¹‹å‰å„²å­˜çš„model æå‡ºä¾†ï¼š
```py
from keras.models import load_model
loaded_model = tf.keras.models.load_model('model.h5')
loaded_model.layers[0].input_shape
loaded_model.evaluate(test_images, test_labels)
```
æœ€å¾Œï¼Œæˆ‘å€‘å¯«äº†å…©å€‹å‡½å¼ï¼Œåˆ†åˆ¥æ˜¯inputå’Œprocessã€‚inputç‚ºä¸€ç°¡å–®å‡½å¼ï¼Œå°‡è¦è¼¸å…¥çš„åœ–ç‰‡åœ¨é›»è…¦å…§çš„è·¯å¾‘ç”¨arrayçš„å½¢å¼å»å„²å­˜ï¼Œå†å°‡å®ƒä¸€ä¸€æå‡ºä¸¦ä¸”è®€å–ã€åˆ¤æ–·ã€‚processå‰‡éœ€è¦ä½¿ç”¨åˆ°OpenCVä¾†è®€å–åœ–ç‰‡ä¸¦ä¸”è½‰ç‚º32x32x3çš„å½¢å¼ï¼Œè—‰ç”±predictä¾†æŠŠä¹‹å‰å­˜å–çš„æ¨¡å‹å¥—åœ¨åœ–ç‰‡ä¸Šã€‚æœ€å¾Œï¼Œé¡¯ç¤ºåˆ†æ•¸æœ€é«˜çš„classåç¨±ã€‚\
å®Œæ•´ç¨‹å¼ç¢¼åœ¨```OwnImageTest.ipynb```ä¸­
```py
import cv2 as cv
def input(pictureArray):
    for i in range(0, len(pictureArray)):
        process(pictureArray[i])

def process (img):
    image = cv.imread(img, cv.IMREAD_COLOR)
    image = cv.resize(image, (32, 32))
    image = image.astype('float32')
    image = image.reshape(1, 32, 32, 3)
    image = 255-image
    image /= 255
    plt.show()
    pred = loaded_model.predict(image.reshape(1, 32, 32, 3), batch_size=1)
    print('Prediction:' + class_names [pred.argmax()])
    img = load_img(img, target_size=(32, 32))
    plt.figure()
    plt.imshow(img) 
    plt.show()

pictureArray = ['C:/Users/user/Test Images/ship1.jpg', 
                'C:/Users/user/Test Images/ship2.jpg', 
		.
		.
		.
	#è¼¸å…¥å¤šçµ„åœ–ç‰‡çš„ç•¶æ¡ˆè·¯å¾‘
					]
input(pictureArray)
```
æˆ‘å€‘å°‡å…«å¼µèˆ¹ä»¥åŠå…­å¼µè²“çš„ç…§ç‰‡æ”¾é€²ç…§ç‰‡ï¼Œçµæœè¨“ç·´æ•ˆæœä¸ç¬¦åˆåœ¨CIFAR-10ä¸Šçš„è¨“ç·´æº–ç¢ºåº¦ã€‚æˆ‘å€‘èªç‚ºåŸå› ä¾†è‡ªæ–¼æˆ‘å€‘çš„è¨“ç·´é›†CIFAR-10æ˜¯32x32çš„åœ–ï¼Œå°è‡´æˆ‘å€‘è‡ªå·±æ”¾é€²å»çš„åœ–ä¹Ÿè¦ç¬¦åˆ32x32çš„æ ¼å¼ï¼Œåœ¨pixelæ•¸ä¸å¤ é«˜çš„æƒ…å½¢ä¸‹é›£ä»¥å»è¾¨è­˜å…¶å¥½å£ï¼Œå› æ­¤éŒ¯èª¤ç‡æ‰æœƒå¦‚æ­¤é«˜ã€‚åœ¨æœªä¾†ï¼Œé™¤äº†å¯ä»¥å˜—è©¦è¨“ç·´å½±åƒè³‡è¨Šé‡æ›´å¤§çš„è³‡æ–™é›†å¤–ï¼Œä¹Ÿè¦å†å¤šå˜—è©¦ä¸åŒçš„è¨“ç·´åƒæ•¸ï¼Œä»¥ç²å¾—æ›´å¥½çš„è¨“ç·´æˆç¸¾ã€‚

